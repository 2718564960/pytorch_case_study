{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96feb677",
   "metadata": {},
   "source": [
    "# 中文序列标注任务（Hugging Face Bert）\n",
    "常见的序列标注任务有：\n",
    "- 命名实体识别 (Named Entity Recognition, NER)：识别出文本中诸如人物、地点、组织等实体，即为所有的 token 都打上实体标签，将其划分到某类实体，或者判定为“非实体”；\n",
    "- 词性标注 (Part-Of-Speech tagging, POS)：为文本中的每一个词语标注上对应的词性，例如名词、动词、形容词等。\n",
    "下面我们以 NER 为例，运用 Transformers 库微调一个基于 BERT 的模型来完成任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397377d0",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "我们选择 1998 年人民日报语料库作为数据集，在其之上训练一个 NER 模型：每次输入一个句子，识别出其中的人物 (PER)、地点 (LOC) 和组织 (ORG)。人民日报语料库标注了大量的语言学信息，可以使用处理工具从中抽取出数据用于分词、NER 等任务，这里我们直接使用处理好的 NER 语料：\n",
    "\n",
    "http://s3.bmio.net/kashgari/china-people-daily-ner-corpus.tar.gz\n",
    "\n",
    "该语料已经划分好了训练集、验证集和测试集，分别对应 example.train、example.dev 和 example.test 文件，其中训练集 / 验证集 / 测试集分别包含 20864 / 2318 / 4636 个句子。语料采用我们在上一篇《快速分词器》中介绍的 IOB2 格式进行标注，一行对应一个字：\n",
    "\n",
    "```\n",
    "海 O\n",
    "钓 O\n",
    "比 O\n",
    "赛 O\n",
    "地 O\n",
    "点 O\n",
    "在 O\n",
    "厦 B-LOC\n",
    "门 I-LOC\n",
    "与 O\n",
    "金 B-LOC\n",
    "门 I-LOC\n",
    "之 O\n",
    "间 O\n",
    "的 O\n",
    "海 O\n",
    "域 O\n",
    "。 O\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d51bd",
   "metadata": {},
   "source": [
    "## 构建数据集\n",
    "我们首先编写继承自 Dataset 类的自定义数据集用于组织样本和标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0238f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "categories = set()\n",
    "\n",
    "class PeopleDaily(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = self.load_data(data_file)\n",
    "    \n",
    "    def load_data(self, data_file):\n",
    "        Data = {}\n",
    "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
    "            for idx, line in enumerate(f.read().split('\\n\\n')):\n",
    "                if not line:\n",
    "                    break\n",
    "                sentence, tags = '', []\n",
    "                for i, c in enumerate(line.split('\\n')):\n",
    "                    word, tag = c.split(' ')\n",
    "                    sentence += word\n",
    "                    if tag[0] == 'B':\n",
    "                        tags.append([i, i, word, tag[2:]]) # Remove the B- or I-\n",
    "                        categories.add(tag[2:])\n",
    "                    elif tag[0] == 'I':\n",
    "                        tags[-1][1] = i\n",
    "                        tags[-1][2] += word\n",
    "                Data[idx] = {\n",
    "                    'sentence': sentence, \n",
    "                    'tags': tags\n",
    "                }\n",
    "        return Data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef44285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '海钓比赛地点在厦门与金门之间的海域。', 'tags': [[7, 8, '厦门', 'LOC'], [10, 11, '金门', 'LOC']]}\n"
     ]
    }
   ],
   "source": [
    "train_data = PeopleDaily('china-people-daily-ner-corpus/example.train')\n",
    "valid_data = PeopleDaily('china-people-daily-ner-corpus/example.dev')\n",
    "test_data = PeopleDaily('china-people-daily-ner-corpus/example.test')\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8315f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-LOC', 2: 'I-LOC', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-PER', 6: 'I-PER'}\n",
      "{'O': 0, 'B-LOC': 1, 'I-LOC': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-PER': 5, 'I-PER': 6}\n"
     ]
    }
   ],
   "source": [
    "id2label = {0:'O'}\n",
    "for c in list(sorted(categories)):\n",
    "    id2label[len(id2label)] = f\"B-{c}\"\n",
    "    id2label[len(id2label)] = f\"I-{c}\"\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf80c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间', '的', '海', '域', '。', '[SEP]']\n",
      "[0 0 0 0 0 0 0 0 1 2 0 1 2 0 0 0 0 0 0 0]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "sentence = '海钓比赛地点在厦门与金门之间的海域。'\n",
    "tags = [[7, 8, '厦门', 'LOC'], [10, 11, '金门', 'LOC']]\n",
    "\n",
    "encoding = tokenizer(sentence, truncation=True)\n",
    "tokens = encoding.tokens()\n",
    "label = np.zeros(len(tokens), dtype=int)\n",
    "for char_start, char_end, word, tag in tags:\n",
    "    token_start = encoding.char_to_token(char_start)\n",
    "    token_end = encoding.char_to_token(char_end)\n",
    "    label[token_start] = label2id[f\"B-{tag}\"]\n",
    "    label[token_start+1:token_end+1] = label2id[f\"I-{tag}\"]\n",
    "\n",
    "print(tokens)\n",
    "print(label)\n",
    "print([id2label[id] for id in label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3e96e",
   "metadata": {},
   "source": [
    "可以看到，通过 char_to_token() 函数，我们成功地将实体标签从原文位置映射到切分后的 token 索引，并且将对应的标签设置为实体编号。\n",
    "\n",
    "实际编写 DataLoader 的批处理函数 collate_fn() 时，我们处理的是一批中的多个样本，因此需要对上面的操作进行扩展。而且由于最终会通过交叉熵损失来优化模型参数，我们还需要将 [CLS]、[SEP]、[PAD] 等特殊 token 对应的标签设为 -100，以便在计算损失时忽略它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5b3f0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([4, 91]), 'token_type_ids': torch.Size([4, 91]), 'attention_mask': torch.Size([4, 91])}\n",
      "batch_y shape: torch.Size([4, 91])\n",
      "{'input_ids': tensor([[ 101,  671,  702,  782, 2339,  868,  749, 1914, 2399, 8024, 4960, 4197,\n",
      "         6206, 1440, 1166, 1333, 1044, 4225, 2634, 4638, 2266,  855, 8024, 1079,\n",
      "         2552, 4638, 5736, 2630,  510, 2659, 2580, 1469, 2606, 2575, 8024, 2600,\n",
      "         3221, 7410, 1048, 4638,  511,  102,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 3219, 1921,  677, 1286, 8024,  809, 2548, 1744, 8131,  686, 5279,\n",
      "         5865, 1399, 4289, 4415, 2110, 2157, 2014, 2442,  185, 2434, 2861, 2548,\n",
      "          185,  840, 4433, 1462, 1399, 4638, 8302, 8159, 3613, 7770, 6862, 4125,\n",
      "         6756, 8024, 1762,  794, 2710, 2225, 7946, 2458, 2518, 3727, 1836, 6854,\n",
      "          704, 6662, 5307,  678, 5855, 1046, 3481, 2336, 4638, 1812, 5650, 2548,\n",
      "         3198, 8024, 4293, 2471, 3322, 6756, 1400, 7481, 4638, 3180, 2145, 6756,\n",
      "         1334, 4960, 4197, 5564, 6758, 8024, 8124, 5688, 6756, 1334,  757, 4685,\n",
      "         1103, 3058,  510, 1363, 1217,  511,  102],\n",
      "        [ 101, 3198,  966, 1909, 1159, 8024, 1744, 2157, 4925, 1218, 2600, 2229,\n",
      "         1469, 3959, 1266, 4689, 1350, 3636, 3727, 2356, 5299, 2768, 4638, 5468,\n",
      "         1394, 6444, 3389, 5299, 3633, 1762, 6999, 4178, 4638, 3636, 3727, 6125,\n",
      "         1928, 2245, 2458, 3291, 3918, 1057, 4638, 6444, 3389,  511,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 101, 3152, 4995, 6432, 8024, 1963, 3362, 3189, 3315, 2190, 5401, 1092,\n",
      "          752, 3118, 3001, 4638, 5745, 1741, 6392, 2137, 1762,  100, 6823,  691,\n",
      "          100, 4638, 6413, 8024, 1378, 3968, 1355, 4495, 2773,  752, 3198, 8024,\n",
      "         3189, 3315, 1469, 5401, 1092, 4638, 1066, 1398, 1092,  752,  792, 1057,\n",
      "         2218,  679, 1377, 6912, 1048,  511,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100],\n",
      "        [-100,    0,    0,    0,    0,    0,    0,    1,    2,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    5,    6,    6,    6,    6,    6,\n",
      "            6,    6,    6,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    1,    2,    2,    0,    0,    1,    2,    0,\n",
      "            0,    0,    0,    1,    2,    2,    2,    2,    0,    1,    2,    2,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0, -100],\n",
      "        [-100,    0,    0,    0,    0,    0,    3,    4,    4,    4,    4,    4,\n",
      "            0,    1,    2,    2,    0,    1,    2,    2,    0,    0,    0,    3,\n",
      "            4,    4,    4,    4,    0,    0,    0,    0,    0,    1,    2,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100],\n",
      "        [-100,    0,    0,    0,    0,    0,    0,    1,    2,    0,    1,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    2,\n",
      "            0,    0,    0,    0,    1,    2,    0,    0,    0,    0,    0,    0,\n",
      "            1,    2,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def collote_fn(batch_samples):\n",
    "    batch_sentence, batch_tags  = [], []\n",
    "    for sample in batch_samples:\n",
    "        batch_sentence.append(sample['sentence'])\n",
    "        batch_tags.append(sample['tags'])\n",
    "    batch_inputs = tokenizer(\n",
    "        batch_sentence, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    batch_label = np.zeros(batch_inputs['input_ids'].shape, dtype=int)\n",
    "    for s_idx, sentence in enumerate(batch_sentence):\n",
    "        encoding = tokenizer(sentence, truncation=True)\n",
    "        batch_label[s_idx][0] = -100\n",
    "        batch_label[s_idx][len(encoding.tokens())-1:] = -100\n",
    "        for char_start, char_end, _, tag in batch_tags[s_idx]:\n",
    "            token_start = encoding.char_to_token(char_start)\n",
    "            token_end = encoding.char_to_token(char_end)\n",
    "            batch_label[s_idx][token_start] = label2id[f\"B-{tag}\"]\n",
    "            batch_label[s_idx][token_start+1:token_end+1] = label2id[f\"I-{tag}\"]\n",
    "    return batch_inputs, torch.tensor(batch_label)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=4, shuffle=False, collate_fn=collote_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=4, shuffle=False, collate_fn=collote_fn)\n",
    "\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print('batch_X shape:', {k: v.shape for k, v in batch_X.items()})\n",
    "print('batch_y shape:', batch_y.shape)\n",
    "print(batch_X)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e585c",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "---------------------\n",
    "### 构建模型\n",
    "采用手工编写 Pytorch 模型的方式来完成：首先利用 Transformers 库加载 BERT 模型，然后接一个全连接层完成分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508ac6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (bert_encoder): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.bert_encoder = AutoModel.from_pretrained(checkpoint)\n",
    "        self.classifier = nn.Linear(768, len(id2label))\n",
    "\n",
    "    def forward(self, x):\n",
    "        bert_output = self.bert_encoder(**x)\n",
    "        logits = self.classifier(bert_output.last_hidden_state)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4706d1",
   "metadata": {},
   "source": [
    "### 优化模型参数\n",
    "与之前一样，我们将每一轮 (Epoch) 分为”训练循环”和”验证/测试循环”，在训练循环中计算损失、优化模型的参数，在验证/测试循环中评估模型的性能。下面我们首先实现训练循环："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4420a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader, start=1):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.permute(0, 2, 1), y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd694d2",
   "metadata": {},
   "source": [
    "注意，与文本分类任务对于每个样本只输出一个预测张量不同，token 分类任务会输出一个预测张量的序列（可以看成是对每个 token 都进行了一次分类），因此使用交叉熵计算模型损失时，不能像之前一样直接将模型的预测结果与标签送入到 CrossEntropyLoss 中进行计算。\n",
    "\n",
    "对于高维度的输出（例如 2D 图像需要按像素计算交叉熵），CrossEntropyLoss 需要将输入维度调整为 \n",
    "(batch,C,d1,d2,…,dK)，其中 C 是类别个数，K 是输入的维度。对于 token 分类任务，就是在 token 序列维度（Keras 中称时间步）上计算交叉熵，因此我们通过 pred.permute(0, 2, 1) 交换后两维，将模型预测结果从(batch,seq,7) 调整为 (batch,7,seq)。\n",
    "\n",
    "验证/测试循环负责评估模型的性能。这里我们借助 seqeval 库进行评估，seqeval 是一个专门用于序列标注评估的 Python 库，支持 IOB、IOB、IOBES 等多种标注格式以及多种评估策略，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029524af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: seqeval in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (from seqeval) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (from seqeval) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.50      0.50      0.50         2\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         3\n",
      "   macro avg       0.75      0.75      0.75         3\n",
      "weighted avg       0.67      0.67      0.67         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "y_true = [['O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "y_pred = [['O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'B-LOC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "\n",
    "print(classification_report(y_true, y_pred, mode='strict', scheme=IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535527f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    true_labels, true_predictions = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            predictions = pred.argmax(dim=-1)\n",
    "            true_labels += [[id2label[int(l)] for l in label if l != -100] for label in y]\n",
    "            true_predictions += [\n",
    "                [id2label[int(p)] for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, y)\n",
    "            ]\n",
    "    print(classification_report(true_labels, true_predictions, mode='strict', scheme=IOB2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f182580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ldap_home/lining/.conda/envs/transformer/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.049675: 100%|██████████| 5216/5216 [03:52<00:00, 22.47it/s]\n",
      "100%|██████████| 580/580 [00:20<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.95      0.95      0.95      1951\n",
      "         ORG       0.89      0.87      0.88       984\n",
      "         PER       0.97      0.98      0.98       884\n",
      "\n",
      "   micro avg       0.94      0.93      0.94      3819\n",
      "   macro avg       0.94      0.93      0.93      3819\n",
      "weighted avg       0.94      0.93      0.94      3819\n",
      "\n",
      "Epoch 2/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.032391: 100%|██████████| 5216/5216 [03:53<00:00, 22.38it/s]\n",
      "100%|██████████| 580/580 [00:20<00:00, 28.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.96      0.96      0.96      1951\n",
      "         ORG       0.92      0.92      0.92       984\n",
      "         PER       0.99      0.98      0.99       884\n",
      "\n",
      "   micro avg       0.96      0.95      0.96      3819\n",
      "   macro avg       0.96      0.95      0.96      3819\n",
      "weighted avg       0.96      0.95      0.96      3819\n",
      "\n",
      "Epoch 3/3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.023824: 100%|██████████| 5216/5216 [03:53<00:00, 22.34it/s]\n",
      "100%|██████████| 580/580 [00:20<00:00, 28.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.97      0.96      0.96      1951\n",
      "         ORG       0.94      0.93      0.93       984\n",
      "         PER       0.98      0.98      0.98       884\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3819\n",
      "   macro avg       0.96      0.96      0.96      3819\n",
      "weighted avg       0.96      0.96      0.96      3819\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epoch_num = 3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    test_loop(valid_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f51bc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': 0.9995534420013428, 'word': '日本外务省', 'start': 0, 'end': 5}, {'entity_group': 'LOC', 'score': 0.9995562434196472, 'word': '日本', 'start': 16, 'end': 18}, {'entity_group': 'PER', 'score': 0.9996896684169769, 'word': '岸田文雄', 'start': 20, 'end': 24}, {'entity_group': 'LOC', 'score': 0.9996272623538971, 'word': '印度', 'start': 34, 'end': 36}, {'entity_group': 'LOC', 'score': 0.9991130828857422, 'word': '柬埔寨', 'start': 37, 'end': 40}]\n"
     ]
    }
   ],
   "source": [
    "sentence = '日本外务省3月18日发布消息称，日本首相岸田文雄将于19至21日访问印度和柬埔寨。'\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sentence, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(pred, dim=-1)[0].tolist()\n",
    "    predictions = pred.argmax(dim=-1)[0].tolist()\n",
    "\n",
    "    pred_label = []\n",
    "    inputs_with_offsets = tokenizer(sentence, return_offsets_mapping=True)\n",
    "    tokens = inputs_with_offsets.tokens()\n",
    "    offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "    idx = 0\n",
    "    while idx < len(predictions):\n",
    "        pred = predictions[idx]\n",
    "        label = id2label[pred]\n",
    "        if label != \"O\":\n",
    "            label = label[2:] # Remove the B- or I-\n",
    "            start, end = offsets[idx]\n",
    "            all_scores = [probabilities[idx][pred]]\n",
    "            # Grab all the tokens labeled with I-label\n",
    "            while (\n",
    "                idx + 1 < len(predictions) and \n",
    "                id2label[predictions[idx + 1]] == f\"I-{label}\"\n",
    "            ):\n",
    "                all_scores.append(probabilities[idx + 1][predictions[idx + 1]])\n",
    "                _, end = offsets[idx + 1]\n",
    "                idx += 1\n",
    "\n",
    "            score = np.mean(all_scores).item()\n",
    "            word = sentence[start:end]\n",
    "            pred_label.append(\n",
    "                {\n",
    "                    \"entity_group\": label,\n",
    "                    \"score\": score,\n",
    "                    \"word\": word,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                }\n",
    "            )\n",
    "        idx += 1\n",
    "    print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112542a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1767ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e48559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-transformer] *",
   "language": "python",
   "name": "conda-env-.conda-transformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
